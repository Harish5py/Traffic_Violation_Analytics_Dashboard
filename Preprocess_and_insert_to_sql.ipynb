{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b5e3692",
   "metadata": {},
   "source": [
    "Chunk-wise data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b913b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1 | Initiated.. | Total shape: (500000, 43)\n",
      "Duplicate shape: (947, 43) | After drop duplicates: (499053, 43)\n",
      "1 | Loaded shape(496473, 45)\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "Iteration: 2 | Initiated.. | Total shape: (500000, 43)\n",
      "Duplicate shape: (723, 43) | After drop duplicates: (499277, 43)\n",
      "2 | Loaded shape(495129, 45)\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "Iteration: 3 | Initiated.. | Total shape: (500000, 43)\n",
      "Duplicate shape: (316, 43) | After drop duplicates: (499684, 43)\n",
      "3 | Loaded shape(498675, 45)\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "Iteration: 4 | Initiated.. | Total shape: (500000, 43)\n",
      "Duplicate shape: (281, 43) | After drop duplicates: (499719, 43)\n",
      "4 | Loaded shape(498533, 45)\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "Iteration: 5 | Initiated.. | Total shape: (70115, 43)\n",
      "Duplicate shape: (28, 43) | After drop duplicates: (70087, 43)\n",
      "5 | Loaded shape(69760, 45)\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "Total shape: 2058570 | Overall time taken: 53.55 minutes\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def replace_make_values(df):\n",
    "\trename_mapper = {}\n",
    "\tmapper1 = {val: \"PORSCHE\" for val in df.loc[((df.Make.str.upper().str.startswith(\"POR\", na=False))\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t |(df.Make.str.upper().str.endswith(\"CHE\", na=False)))\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t &(~df.Make.isin([\"APACHE\", \"CHE\"])), \"Make\"].unique()}\n",
    "\trename_mapper.update(mapper1)\n",
    "\tmapper2 = {val: \"FORD\" for val in df.loc[(df.Make.str.upper().str.startswith(\"FOR\", na=False))\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   |(df.Make.str.upper().str.endswith(\"ORD\", na=False))\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   , \"Make\"].unique()}\n",
    "\trename_mapper.update(mapper2)\n",
    "\tmapper3 = {val: \"TOWN & COUNTRY\" for val in df.loc[(df.Make.str.upper().str.startswith(\"TOW\", na=False))\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t |(df.Make.str.upper().str.endswith(\"TRY\", na=False))\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t , \"Make\"].unique()}\n",
    "\trename_mapper.update(mapper3)\n",
    "\tmapper4 = {val: \"TOYOTA\" for val in df.loc[(df.Make.str.upper().str.startswith(\"TOY\", na=False))\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t |(df.Make.str.upper().str.endswith(\"OTA\", na=False))\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t , \"Make\"].unique()}\n",
    "\tmapper4.update({\"YOYOYA\":\"TOYOTA\", \n",
    "\t\t\t\t\t\"TOTOYOT\":\"TOYOTA\", \n",
    "\t\t\t\t\t\"YOYO\":\"TOYOTA\", \n",
    "\t\t\t\t\t\"OYOYA\":\"TOYOTA\", \n",
    "\t\t\t\t\t\"OYO\":\"TOYOTA\"})\n",
    "\trename_mapper.update(mapper4)\n",
    "\tmapper5 = {val: \"MINI COOPER\" for val in df.loc[(df.Make.str.upper().str.startswith(\"MINI\", na=False))\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t  |(df.Make.str.upper().str.endswith(\"PER\", na=False))\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t  , \"Make\"].unique()}\n",
    "\tmapper5.update({\"MNNI\":\"MINI COOPER\"})\n",
    "\trename_mapper.update(mapper5)\n",
    "\tmapper6 = {val: \"CHEVROLET\" for val in df.loc[df.Make.str.upper().str.startswith(\"CHEV\", na=False)\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t|df.Make.str.upper().str.endswith(\"LET\", na=False)\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t, \"Make\"].unique()}\n",
    "\tmapper6.update({\"CHE\":\"CHEVROLET\",\n",
    "\t\t\t\t\t\"CHVERLOET\":\"CHEVROLET\",\n",
    "\t\t\t\t\t\"CEHV\":\"CHEVROLET\", \n",
    "\t\t\t\t\t\"CHV\":\"CHEVROLET\",\n",
    "\t\t\t\t\t\"CHRV\":\"CHEVROLET\",\n",
    "\t\t\t\t\t\"CEV\":\"CHEVROLET\",\n",
    "\t\t\t\t\t\"XCHRV\":\"CHEVROLET\",\n",
    "\t\t\t\t\t\"SHEV\":\"CHEVROLET\",\n",
    "\t\t\t\t\t\"VHEV\":\"CHEVROLET\",\n",
    "\t\t\t\t\t\"HEV\":\"CHEVROLET\", \n",
    "\t\t\t\t\t\"CVEV\":\"CHEVROLET\", \n",
    "\t\t\t\t\t\"CHE V\":\"CHEVROLET\",\n",
    "\t\t\t\t\t\"CNEV\":\"CHEVROLET\",\n",
    "\t\t\t\t\t\"CGEV\":\"CHEVROLET\", \n",
    "\t\t\t\t\t\"C HEV\":\"CHEVROLET\",\n",
    "\t\t\t\t\t\"HCHEV\":\"CHEVROLET\", \n",
    "\t\t\t\t\t\"CJEV\":\"CHEVROLET\",\n",
    "\t\t\t\t\t\"CHEYV\":\"CHEVROLET\", \n",
    "\t\t\t\t\t\"CEHEV\":\"CHEVROLET\",\n",
    "\t\t\t\t\t\"CHEROVET\":\"CHEVROLET\"})\n",
    "\trename_mapper.update(mapper6)\n",
    "\tmapper7 = {val: \"MASERATI\" for val in df.loc[df.Make.str.upper().str.startswith(\"MAS\", na=False)\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t   |df.Make.str.upper().str.endswith(\"RATI\", na=False)\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t   , \"Make\"].unique()}\n",
    "\tmapper7.update({\"MAZERADI\":\"MASERATI\",\n",
    "\t \"MAZERATTI\":\"MASERATI\",\n",
    "\t \"MAZARATTI\":\"MASERATI\",\n",
    "\t \"MSAERADI\":\"MASERATI\"})\n",
    "\trename_mapper.update(mapper7)\n",
    "\tmapper8 = {val: \"MAZDA\" for val in df.loc[df.Make.str.upper().str.startswith(\"MAZ\", na=False)\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t|df.Make.str.upper().str.endswith(\"ZDA\", na=False)\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t, \"Make\"].unique()}\n",
    "\tmapper8.update({\"MADZA\":\"MAZDA\",\n",
    "\t \"MADA\":\"MAZDA\",\n",
    "\t \"MADZ\":\"MAZDA\",\n",
    "\t\"MAVDA\":\"MAZDA\",\n",
    "\t\"MZADA\":\"MAZDA\",\n",
    "\t\"MARCZ\":\"MAZDA\",\n",
    "\t\"MACDA\":\"MAZDA\",\n",
    "\t \"MAXDA\":\"MAZDA\"})\n",
    "\trename_mapper.update(mapper8)\n",
    "\tmapper9 = {val: \"HYUNDAI\" for val in df.loc[df.Make.str.upper().str.startswith(\"HY\", na=False)\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t  |df.Make.str.upper().str.endswith(\"DAI\", na=False)\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t  , \"Make\"].unique()}\n",
    "\tmapper9.update({\n",
    "\t\t\"HUNDYAI\":\"HYUNDAI\",\n",
    "\t\t\"HUYN\":\"HYUNDAI\",\n",
    "\t\t\"HUNDAY\":\"HYUNDAI\",\n",
    "\t\t\"HUND\":\"HYUNDAI\",\n",
    "\t\t\"HUY\":\"HYUNDAI\",\n",
    "\t\t\"HUNDYI\":\"HYUNDAI\",\n",
    "\t\t\"HUNDY\":\"HYUNDAI\",\n",
    "\t\t\"HUYAND\":\"HYUNDAI\",\n",
    "\t\t\"HUNY\":\"HYUNDAI\",\n",
    "\t\t\"HUNYDA\":\"HYUNDAI\",\n",
    "\t\t\"HUYNDAY\":\"HYUNDAI\",\n",
    "\t\t\"HUYNDA\":\"HYUNDAI\",\n",
    "\t\t\"HUYNDIA\":\"HYUNDAI\",\n",
    "\t\t\"HUYUND\":\"HYUNDAI\",\n",
    "\t\t\"HUYDIA\":\"HYUNDAI\",\n",
    "\t\t\"HUYN 2D\":\"HYUNDAI\",\n",
    "\t\t\"HUNDI\":\"HYUNDAI\",\n",
    "\t\t\"HUN\":\"HYUNDAI\",\n",
    "\t\t\"HUYND\":\"HYUNDAI\",\n",
    "\t\t\"HUYANDI\":\"HYUNDAI\",\n",
    "\t\t\"HUINDAY\":\"HYUNDAI\",\n",
    "\t\t\"HUYUNDA\":\"HYUNDAI\",\n",
    "\t\t\"HUYNDI\":\"HYUNDAI\",\n",
    "\t\t\"HUYUN\":\"HYUNDAI\",\n",
    "\t\t\"HUYUNDI\":\"HYUNDAI\",\n",
    "\t\t\"HUDAYI\":\"HYUNDAI\",\n",
    "\t\t\"HUNDAYI\":\"HYUNDAI\",\n",
    "\t\t\"HUUNDIA\":\"HYUNDAI\",\n",
    "\t\t\"HUNAY\":\"HYUNDAI\",\n",
    "\t\t\"HUYNA\":\"HYUNDAI\",\n",
    "\t\t\"HHYUNDA\":\"HYUNDAI\",\n",
    "\t\t\"HIYUNDA\":\"HYUNDAI\",\n",
    "\t\t\"HIUNDA\":\"HYUNDAI\",\n",
    "\t\t\"HAYUNDI\":\"HYUNDAI\"\n",
    "\t})\n",
    "\trename_mapper.update(mapper9)\n",
    "\tmapper10 = {val: \"HONDA\" for val in df.loc[\n",
    "\t\t((df.Make.str.upper().str.startswith(\"HON\", na=False))|\n",
    "\t\t (df.Make.str.upper().str.endswith(\"DA\", na=False)))&\n",
    "\t\t (~df.Make.str.upper().isin([\"MAZDA\", \"TESLDA\", \"KIDA\", \"FLORIDA\", \"ACURDA\", \"ARMADA\", \"SUDA\"])), \n",
    "\t\t\"Make\"].unique()}\n",
    "\trename_mapper.update(mapper10)\n",
    "\tmapper11 = {val: \"TESLA\" for val in df.loc[\n",
    "\t\t((df.Make.str.upper().str.startswith(\"TES\", na=False))|\n",
    "\t\t (df.Make.str.upper().str.endswith(\"SLA\", na=False))), \"Make\"].unique()}\n",
    "\tmapper11.update({\"TSELA\": \"TESLA\",\n",
    "\t\t\t\t\t\"TELSA\": \"TESLA\",\n",
    "\t\t\t\t\t\"TELSA`\": \"TESLA\",\n",
    "\t\t\t\t\t\"TSELA\": \"TESLA\"})\n",
    "\trename_mapper.update(mapper11)\n",
    "\tmapper12 = {val: \"SUZUKI\" for val in df.loc[\n",
    "\t\t((df.Make.str.upper().str.startswith(\"SUZ\", na=False))|\n",
    "\t\t (df.Make.str.upper().str.endswith(\"UKI\", na=False))), \"Make\"].unique()}\n",
    "\trename_mapper.update(mapper12)\n",
    "\tmapper13 = {val: \"SUBARU\" for val in df.loc[\n",
    "\t\t((df.Make.str.upper().str.startswith(\"SUB\", na=False))|\n",
    "\t\t (df.Make.str.upper().str.endswith(\"ARU\", na=False))), \"Make\"].unique()}\n",
    "\trename_mapper.update(mapper13)\n",
    "\tmapper14 = {val: \"VOLKSWAGEN\" for val in df.loc[\n",
    "\t\t((df.Make.str.upper().str.startswith(\"VOLK\", na=False))|\n",
    "\t\t (df.Make.str.upper().str.endswith(\"AGEN\", na=False))|\n",
    "\t\t (df.Make.str.upper().str.contains(\"SWA\", na=False))), \"Make\"].unique()}\n",
    "\tmapper14.update({\"VOLWAGON\":\"VOLKSWAGEN\",\n",
    "\t\t\t\t\t \"VOLSKWAGON\":\"VOLKSWAGEN\",\n",
    "\t\t\t\t\t \"VOLT WAGON\":\"VOLKSWAGEN\",\n",
    "\t\t\t\t\t \"VOLTWAGON\":\"VOLKSWAGEN\",\n",
    "\t\t\t\t\t \"VOLTS WAGON\":\"VOLKSWAGEN\",\n",
    "\t\t\t\t\t \"VOLSK\": \"VOLKSWAGEN\",\n",
    "\t\t\t\t\t \"VOLSKS\":\"VOLKSWAGEN\",\n",
    "\t\t\t\t\t \"VOLLKS\":\"VOLKSWAGEN\",\n",
    "\t\t\t\t\t \"VOLS\":\"VOLKSWAGEN\",\n",
    "\t\t\t\t\t \"VOLTZ\":\"VOLKSWAGEN\",\n",
    "\t\t\t\t\t \"VOLTS\":\"VOLKSWAGEN\",\n",
    "\t\t\t\t\t \"VOLWAG\":\"VOLKSWAGEN\",\n",
    "\t\t\t\t\t \"VOLZ\":\"VOLKSWAGEN\",\n",
    "\t\t\t\t\t \"VOLSW\":\"VOLKSWAGEN\",\n",
    "\t\t\t\t\t \"VOLT\":\"VOLKSWAGEN\",\n",
    "\t\t\t\t\t \"VOKS\":\"VOLKSWAGEN\",\n",
    "\t\t\t\t\t \"VOK\":\"VOLKSWAGEN\",\n",
    "\t\t\t\t\t \"VO;KS\":\"VOLKSWAGEN\",\n",
    "\t\t\t\t\t \"VOIKS\":\"VOLKSWAGEN\",\n",
    "\t\t\t\t\t \"VOKLS\":\"VOLKSWAGEN\",\n",
    "\t\t\t\t\t \"VOKWAGON\":\"VOLKSWAGEN\",\n",
    "\t\t\t\t\t \"VLOK\":\"VOLKSWAGEN\",\n",
    "\t\t\t\t\t \"VO;K\":\"VOLKSWAGEN\",\n",
    "\t\t\t\t\t \"VOILKS\":\"VOLKSWAGEN\",\n",
    "\t\t\t\t\t \"VLOKS\":\"VOLKSWAGEN\", \n",
    "\t\t\t\t\t \"VOTLS WAGON\":\"VOLKSWAGEN\", \n",
    "\t\t\t\t\t \"VOWLKS\":\"VOLKSWAGEN\"})\n",
    "\trename_mapper.update(mapper14)\n",
    "\tmapper15 = {val: \"VOLVO\" for val in df.loc[\n",
    "\t\t((df.Make.str.upper().str.startswith(\"VOLV\", na=False))|\n",
    "\t\t (df.Make.str.upper().str.endswith(\"LVO\", na=False))|\n",
    "\t\t (df.Make.str.upper().str.contains(\"OLV\", na=False))), \"Make\"].unique()}\n",
    "\tmapper15.update({\"VOVLO\": \"VOLVO\", \n",
    "\t\t\t\t\t \"VOVO\": \"VOLVO\", \n",
    "\t\t\t\t\t \"VOV\": \"VOLVO\", \n",
    "\t\t\t\t\t \"VOVL\": \"VOLVO\", \n",
    "\t\t\t\t\t \"VOVLV\": \"VOLVO\", \n",
    "\t\t\t\t\t \"VOVOL\": \"VOLVO\",\n",
    "\t\t\t\t\t \"VOL\": \"VOLVO\", \n",
    "\t\t\t\t\t \"VOLO\": \"VOLVO\", \n",
    "\t\t\t\t\t \"VOL VO\": \"VOLVO\", \n",
    "\t\t\t\t\t \"VOLCO\": \"VOLVO\", \n",
    "\t\t\t\t\t \"VOLOV\": \"VOLVO\",\n",
    "\t\t\t\t\t \"VOLJS\": \"VOLVO\", \n",
    "\t\t\t\t\t \"VOL;VO\": \"VOLVO\", \n",
    "\t\t\t\t\t \"VOLOVO\": \"VOLVO\", \n",
    "\t\t\t\t\t \"VILV\": \"VOLVO\", \n",
    "\t\t\t\t\t \"V0LV\":\"VOLVO\",\n",
    "\t\t\t\t\t \"VLOVO\":\"VOLVO\",\n",
    "\t\t\t\t\t \"VLV\":\"VOLVO\"})\n",
    "\trename_mapper.update(mapper15)\n",
    "\tmapper16 = {val: \"MERCURY\" for val in df.loc[\n",
    "\t\t((df.Make.str.upper().str.startswith(\"MERCU\", na=False))\n",
    "\t\t |(df.Make.str.upper().str.endswith(\"CURY\", na=False))), \"Make\"].unique()}\n",
    "\tmapper16.update({\"MECRURY\":\"MERCURY\",\n",
    "\t\t\t\t\t \"MECURT\":\"MERCURY\",\n",
    "\t\t\t\t\t \"MEC\":\"MERCURY\",\n",
    "\t\t\t\t\t \"MECE\":\"MERCURY\"})\n",
    "\trename_mapper.update(mapper16)\n",
    "\tmapper17 = {val: \"ACURA\" for val in df.loc[\n",
    "\t\t((df.Make.str.upper().str.startswith(\"ACU\", na=False))\n",
    "\t\t |(df.Make.str.upper().str.endswith(\"URA\", na=False))\n",
    "\t\t |(df.Make.str.upper().str.contains(\"CURA\", na=False))\n",
    "\t\t ), \"Make\"].unique()}\n",
    "\trename_mapper.update(mapper17)\n",
    "\tmapper18 = {val: \"SATURN\" for val in df.loc[\n",
    "\t\t((df.Make.str.upper().str.startswith(\"SAT\", na=False))\n",
    "\t\t |(df.Make.str.upper().str.endswith(\"URN\", na=False))\n",
    "\t\t |(df.Make.str.upper().str.contains(\"ATUR\", na=False))\n",
    "\t\t ), \"Make\"].unique()}\n",
    "\trename_mapper.update(mapper18)\n",
    "\tmapper19 = {val: \"MERCEDES\" for val in df.loc[\n",
    "\t\t((df.Make.str.upper().str.startswith(\"MERC\", na=False))\n",
    "\t\t |(df.Make.str.upper().str.endswith(\"DES\", na=False))\n",
    "\t\t |(df.Make.str.upper().str.contains(\"CED\", na=False))\n",
    "\t\t ), \"Make\"].unique()}\n",
    "\tmapper19.update({\"MERZ\":\"MERCEDES\", \n",
    "\t\t\t\t\t \"BENZ\":\"MERCEDES\", \n",
    "\t\t\t\t\t \"MERZ C300\":\"MERCEDES\"})\n",
    "\trename_mapper.update(mapper19)\n",
    "\tmapper20 = {val: \"HUMMER\" for val in [\"HUMMER\", \"HUMM\", \"HUMER\", \"HUM\"]}\n",
    "\trename_mapper.update(mapper20)\n",
    "\tmapper21 = {val: \"HUDSON\" for val in [\"HUDS\"]}\n",
    "\trename_mapper.update(mapper21)\n",
    "\tmapper22 = {val: \"HARLEY DAVIDSON\" for val in df.loc[\n",
    "\t\t((df.Make.str.upper().str.startswith(\"HAR\", na=False))\n",
    "\t\t |(df.Make.str.upper().str.endswith(\"IDSON\", na=False))\n",
    "\t\t ), \"Make\"].unique()}\n",
    "\trename_mapper.update(mapper22)\n",
    "\tmapper23 = {val: \"NISSAN\" for val in df.loc[\n",
    "\t\t((df.Make.str.upper().str.startswith(\"NIS\", na=False))\n",
    "\t\t |(df.Make.str.upper().str.endswith(\"SAN\", na=False))\n",
    "\t\t ), \"Make\"].unique()}\n",
    "\trename_mapper.update(mapper23)\n",
    "\tmapper24 = {val: \"RANGE ROVER\" for val in [\"RANGE ROVER\", \"ROVER\", \"RANGER ROVER\", \"RANGE\", \"RANGEROVER\", \n",
    "\t\t\t\t\t\t\t\t\t\t\t   \"RNG ROVER\", \"RANGE ROIVER\", \"RANGE ROGER\", \"RANGE  ROVER\", \n",
    "\t\t\t\t\t\t\t\t\t\t\t   \"RANGE ROV\", \"RANGER\", \"RANG ROVER\", \"RANGROVER\", \"RANGE RVR\", \n",
    "\t\t\t\t\t\t\t\t\t\t\t   \"RANGE OVER\", \"RANGE RV\", \"RANGE R\", \"RANFE ROVER\", \"RANGE ROVR\", \n",
    "\t\t\t\t\t\t\t\t\t\t\t   \"RAND ROVER\", \"RANGE RVER\", \"RANGR ROVER\", \"RANDGE ROVER\", \"RAGE ROVER\", \n",
    "\t\t\t\t\t\t\t\t\t\t\t   \"RAINGE ROVER\", \"RANGERVR\", \"RANGEVROVER\", \"RANGE ROVERY\", \"RANGE ROVE\", \n",
    "\t\t\t\t\t\t\t\t\t\t\t   \"RANGE ROVERLNDR\", \"RANGSUV\"]}\n",
    "\trename_mapper.update(mapper24)\n",
    "\tmapper25 = {val: \"LAND ROVER\" for val in [\"LANDROVER\", \"LAND ROVER\", \"LAMD ROVER\", \"LAN ROVER\", \"LANROVER\", \n",
    "\t\t\t\t\t\t\t\t\t\t\t  \"LANDR\", \"LAND RV\", \";AND ROVER\", \"LNDROVER\", \"LABD ROVER\", \n",
    "\t\t\t\t\t\t\t\t\t\t\t  \"LAND RVR\", \"LAND ROVE\", \"LAND OVER\", \"LAND ROV\", \"LAND\", \"LANDOVER\", \n",
    "\t\t\t\t\t\t\t\t\t\t\t  \"LAND  ROVER\", \"LND ROVER\", \"L ROVER\", \"LAND RAOVER\", \"LAND EOVER\", \n",
    "\t\t\t\t\t\t\t\t\t\t\t  \"LA ND ROVER\", \"LANDRO\", \"LAND ROVR\", \"LANDROV\", \"LANDVAL2013\", \"LANDROVE\", \n",
    "\t\t\t\t\t\t\t\t\t\t\t  \"LANDDROVER\", \"LMAND ROVER\", \"LAND ROVWR\", \"LANDRVR\", \"LAND RVER\", \"LANDROER\", \n",
    "\t\t\t\t\t\t\t\t\t\t\t  \"LAND RANGER\", \"LANDR ROVER\",\"LAD ROVER\", \"LAND ROER\", \"LAND-ROVER\", \"LAND5ROVER\", \n",
    "\t\t\t\t\t\t\t\t\t\t\t  \"LAND RVT\", \"LAND ROAVER\"]}\n",
    "\trename_mapper.update(mapper25)\n",
    "\tmapper26 = {val: \"KAWASAKI\" for val in df.loc[\n",
    "\t\t((df.Make.str.upper().str.startswith(\"KAWA\", na=False))\n",
    "\t\t |(df.Make.str.upper().str.endswith(\"SAKI\", na=False))\n",
    "\t\t ), \"Make\"].unique()}\n",
    "\tmapper26.update({val:\"KAWASAKI\" for val in [\"KAWK\", \"KAWKASKI\"]})\n",
    "\trename_mapper.update(mapper26)\n",
    "\tmapper27 = {val: \"LONGBOW\" for val in [\"NINGBO\", \"LONGBO\", \"LONG\"]}\n",
    "\trename_mapper.update(mapper27)\n",
    "\tmapper28 = {val: \"LINCOLN\" for val in [\"LINCOLN\", \"LINCOLIN\", \"LINCON\", \"LICOLN\", \"LINCOL\", \"INCOLN\",\n",
    "\t\"LINCONLN\", \"LONCOLN\", \"LINCOLNN\", \"LINCO\", \"LINCONL\", \"LIINCOLN\", \"LINCOLB\", \"LINCOKN\", \"LINCOLCN\", \n",
    "\t\"LINNCOLN\", \"LINCOLM\", \"LNCOLIN\", \"LONCOLN\", \"LONCIN 110CC\", \"LINC\"]}\n",
    "\trename_mapper.update(mapper28)\n",
    "\tmapper29 = {val: \"MITSUBISHI\" for val in df.loc[\n",
    "\t\t((df.Make.str.upper().str.startswith(\"MITS\", na=False))\n",
    "\t\t |(df.Make.str.upper().str.endswith(\"ISHI\", na=False))\n",
    "\t\t |(df.Make.str.upper().str.contains(\"TSUBI\", na=False))\n",
    "\t\t ), \"Make\"].unique()}\n",
    "\tmapper29.update({\"MITZ\":\"MITSUBISHI\"})\n",
    "\trename_mapper.update(mapper29)\n",
    "\tmapper30 = {val: \"LEXUS\" for val in df.loc[\n",
    "\t\t((df.Make.str.upper().str.startswith(\"LEX\", na=False))\n",
    "\t\t |(df.Make.str.upper().str.endswith(\"XUS\", na=False))\n",
    "\t\t |(df.Make.str.upper().str.contains(\"EXU\", na=False))\n",
    "\t\t ), \"Make\"].unique()}\n",
    "\trename_mapper.update(mapper30)\n",
    "\tmapper31 = {val: \"BMW\" for val in df.loc[\n",
    "\t\t((df.Make.str.upper().str.contains(\"BM\", na=False))\n",
    "\t\t |(df.Make.str.upper().str.contains(\"MW\", na=False))\n",
    "\t\t |(df.Make.str.upper().str.contains(\"BW\", na=False))\n",
    "\t\t ), \"Make\"].unique()}\n",
    "\trename_mapper.update(mapper31)\n",
    "\tmapper32 = {val: \"FIAT\" for val in df.loc[\n",
    "\t\t((df.Make.str.upper().str.startswith(\"FIA\", na=False))\n",
    "\t\t |(df.Make.str.upper().str.endswith(\"IAT\", na=False))\n",
    "\t\t ), \"Make\"].unique()}\n",
    "\trename_mapper.update(mapper32)\n",
    "\tmapper33 = {val: \"PONTIAC\" for val in df.loc[\n",
    "\t\t((df.Make.str.upper().str.startswith(\"PON\", na=False))\n",
    "\t\t |(df.Make.str.upper().str.endswith(\"TIAC\", na=False))\n",
    "\t\t ), \"Make\"].unique()}\n",
    "\trename_mapper.update(mapper33)\n",
    "\tmapper34 = {val: \"CADILLAC\" for val in df.loc[\n",
    "\t\t((df.Make.str.upper().str.startswith(\"CAD\", na=False))\n",
    "\t\t |(df.Make.str.upper().str.endswith(\"LAC\", na=False))\n",
    "\t\t ), \"Make\"].unique()}\n",
    "\trename_mapper.update(mapper34)\n",
    "\tmapper35 = {val: \"JIANGSU BAODIAO\" for val in df.loc[\n",
    "\t\t((df.Make.str.upper().str.startswith(\"JIAN\", na=False))\n",
    "\t\t |(df.Make.str.upper().str.endswith(\"DIAO\", na=False))\n",
    "\t\t ), \"Make\"].unique()}\n",
    "\trename_mapper.update(mapper35)\n",
    "\tmapper36 = {val: \"KAUFFMAN\" for val in df.loc[\n",
    "\t\t((df.Make.str.upper().str.startswith(\"KAU\", na=False))\n",
    "\t\t |(df.Make.str.upper().str.endswith(\"FMAN\", na=False))\n",
    "\t\t ), \"Make\"].unique()}\n",
    "\trename_mapper.update(mapper36)\n",
    "\tmapper37 = {val: \"ZHEJIANG JIAJUE\" for val in df.loc[\n",
    "\t\t((df.Make.str.upper().str.startswith(\"ZHEJ\", na=False))\n",
    "\t\t |(df.Make.str.upper().str.endswith(\"AJUE\", na=False))\n",
    "\t\t |(df.Make.str.upper().str.contains(\"JIAJ\", na=False))\n",
    "\t\t ), \"Make\"].unique()}\n",
    "\trename_mapper.update(mapper37)\n",
    "\tmapper38 = {val: \"RIVIAN\" for val in df.loc[\n",
    "\t\t((df.Make.str.upper().str.startswith(\"RIVI\", na=False))\n",
    "\t\t ), \"Make\"].unique()}\n",
    "\trename_mapper.update(mapper38)\n",
    "\tmapper39 = {val: \"DUCATI\" for val in df.loc[\n",
    "\t\t((df.Make.str.upper().str.startswith(\"DUCA\", na=False))\n",
    "\t\t ), \"Make\"].unique()}\n",
    "\tmapper39.update({\"DUCOTI\":\"DUCATI\"})\n",
    "\trename_mapper.update(mapper39)\n",
    "\tmapper40 = {val: \"KIA\" for val in df.loc[\n",
    "\t\t((df.Make.str.upper().str.contains(\"KIA\", na=False))\n",
    "\t\t ), \"Make\"].unique()}\n",
    "\tmapper40.update({val:\"KIA\" for val in [\"KIIA\", \"KIS\"]})\n",
    "\trename_mapper.update(mapper40)\n",
    "\tmapper41 = {val: \"PIAGGIO\" for val in df.loc[\n",
    "\t\t((df.Make.str.upper().str.startswith(\"PIA\", na=False))\n",
    "\t\t |(df.Make.str.upper().str.contains(\"GIO\", na=False))\n",
    "\t\t ), \"Make\"].unique()}\n",
    "\trename_mapper.update(mapper41)\n",
    "\tmapper42 = {val: \"AUDI\" for val in df.loc[\n",
    "\t\t((df.Make.str.upper().str.startswith(\"AUDI\", na=False))\n",
    "\t\t |(df.Make.str.upper().str.endswith(\"UDI\", na=False))\n",
    "\t\t ), \"Make\"].unique()}\n",
    "\tmapper42.update({\"AUID\":\"AUDI\"})\n",
    "\trename_mapper.update(mapper42)\n",
    "\tmapper43 = {val: \"QIAN\" for val in df.loc[\n",
    "\t\t((df.Make.str.upper().str.contains(\"QIAN\", na=False))\n",
    "\t\t ), \"Make\"].unique()}\n",
    "\trename_mapper.update(mapper43)\n",
    "\tmapper44 = {val: \"RAM\" for val in df.loc[\n",
    "\t\t((df.Make.str.upper().str.contains(\"RAM\", na=False))\n",
    "\t\t ), \"Make\"].unique()}\n",
    "\trename_mapper.update(mapper44)\n",
    "\tmapper45 = {val: \"SCION\" for val in df.loc[\n",
    "\t\t((df.Make.str.upper().str.contains(\"SCION\", na=False))\n",
    "\t\t ), \"Make\"].unique()}\n",
    "\trename_mapper.update(mapper45)\n",
    "\tmapper46 = {val: \"JAGUAR\" for val in df.loc[\n",
    "\t\t(df.Make.str.upper().str.startswith(\"JAG\", na=False))\n",
    "\t\t|(df.Make.str.upper().str.endswith(\"UAR\", na=False))\n",
    "\t\t|(df.Make.str.upper().str.contains(\"GUAR\", na=False))\n",
    "\t\t , \"Make\"].unique()}\n",
    "\trename_mapper.update(mapper46)\n",
    "\tmapper47 = {val: \"WESTERN STAR\" for val in ['WSTR', 'WEST', 'WESTERN STAR', 'STAR',\n",
    "\t\t   'FIVE STAR', 'WESTERN', 'WEST TK', 'HOME STAR',\n",
    "\t\t   'WESTERN STA', 'WESTERN-STAR']}\n",
    "\trename_mapper.update(mapper47)\n",
    "\tmapper48 = {val: \"DODGE\" for val in df.loc[\n",
    "\t\t(df.Make.str.upper().str.contains(\"DODGE\", na=False))\n",
    "\t\t|(df.Make.str.upper().str.startswith(\"DOD\", na=False))\n",
    "\t\t|(df.Make.str.upper().str.endswith(\"DGE\", na=False))\n",
    "\t\t , \"Make\"].unique()}\n",
    "\trename_mapper.update(mapper48)\n",
    "\tmapper49 = {val: \"INFINITI\" for val in df.loc[\n",
    "\t\t(df.Make.str.upper().str.contains(\"INFI\", na=False))\n",
    "\t\t , \"Make\"].unique()}\n",
    "\trename_mapper.update(mapper49)\n",
    "\tmapper50 = {val: \"JEEP\" for val in df.loc[\n",
    "\t\t(df.Make.str.upper().str.startswith(\"JE\", na=False))\n",
    "\t\t|(df.Make.str.upper().str.endswith(\"EP\", na=False))\n",
    "\t\t , \"Make\"].unique()}\n",
    "\trename_mapper.update(mapper50)\n",
    "\tmapper51 = {val: \"INTERNATIONAL\" for val in df.loc[\n",
    "\t\t(df.Make.str.upper().str.startswith(\"INTER\", na=False))\n",
    "\t\t|(df.Make.str.upper().str.endswith(\"TIONAL\", na=False))\n",
    "\t\t , \"Make\"].unique()}\n",
    "\tmapper51.update({\"INTL\":\"INTERNATIONAL\"})\n",
    "\trename_mapper.update(mapper51)\n",
    "\tmapper52 = {val: \"THOMAS\" for val in df.loc[\n",
    "\t\t(df.Make.str.upper().str.startswith(\"THOM\", na=False))\n",
    "\t\t|(df.Make.str.upper().str.endswith(\"OMAS\", na=False))\n",
    "\t\t|(df.Make.str.upper().str.contains(\"OMA\", na=False))\n",
    "\t\t , \"Make\"].unique()}\n",
    "\tmapper52.update({\"THMS\":\"THOMAS\"})\n",
    "\trename_mapper.update(mapper52)\n",
    "\tmapper53 = {val: \"CHRYSLER\" for val in df.loc[\n",
    "\t\t(df.Make.str.upper().str.contains(\"CHRY\", na=False))\n",
    "\t\t , \"Make\"].unique()}\n",
    "\trename_mapper.update(mapper53)\n",
    "\tmapper54 = {val: \"ISUZU\" for val in df.loc[\n",
    "\t\t(df.Make.str.upper().str.startswith(\"ISU\", na=False))\n",
    "\t\t|(df.Make.str.upper().str.endswith(\"UZU\", na=False))\n",
    "\t\t , \"Make\"].unique()}\n",
    "\trename_mapper.update(mapper54)\n",
    "\tmapper55 = {val: \"GENESIS\" for val in ['GENESIS', 'GENE', 'HENESIS', 'GENESS']}\n",
    "\trename_mapper.update(mapper55)\n",
    "\tmapper56 = {val: \"TEXAS PRIDE\" for val in ['TEXAS PRIDE', 'RIDE', 'TEXS', 'TEXA']}\n",
    "\trename_mapper.update(mapper56)\n",
    "\tmapper57 = {val: \"FREIGHTLINER\" for val in df.loc[\n",
    "\t\t(df.Make.str.upper().str.startswith(\"FREI\", na=False))\n",
    "\t\t|(df.Make.str.upper().str.endswith(\"LINER\", na=False))\n",
    "\t\t|(df.Make.str.upper().str.contains(\"GHTL\", na=False))\n",
    "\t\t , \"Make\"].unique()}\n",
    "\trename_mapper.update(mapper57)\n",
    "\tmapper58 = {val: \"FISKER\" for val in ['FISKER', 'FISK']}\n",
    "\trename_mapper.update(mapper58)\n",
    "\tmapper59 = {val: \"MACK\" for val in ['MACK', 'MACH', 'MACL', 'MAC',\n",
    "\t\t   'MACK TRUCK']}\n",
    "\trename_mapper.update(mapper59)\n",
    "\tmapper60 = {val: \"WHITE\" for val in df.loc[\n",
    "\t\t(df.Make.str.upper().str.startswith(\"WHIT\", na=False))\n",
    "\t\t|(df.Make.str.upper().str.endswith(\"HITE\", na=False))\n",
    "\t\t , \"Make\"].unique()}\n",
    "\trename_mapper.update(mapper60)\n",
    "\tdf.Make = df.Make.replace(rename_mapper)\n",
    "\treturn df\n",
    "\t\n",
    "def columnwise_cleaning(df):\n",
    "\tdf[\"DateTime Of Stop\"] = pd.to_datetime(df['Date Of Stop'] +\" \"+ df['Time Of Stop'], errors=\"raise\")\n",
    "\tdf[\"Date Of Stop\"] = pd.to_datetime(df['Date Of Stop'], errors=\"raise\")\n",
    "\tdf[\"Description\"] = df.Description.str.lstrip().str.rstrip().str.lower()\n",
    "\tdf[\"Location\"] = df.Location.str.replace(\"@\", \"/\")\n",
    "\tdf[\"Latitude\"] = pd.to_numeric(df.Latitude).replace(0, np.nan).apply(lambda x: round(x,2)) #remove impossible coordinates\n",
    "\tdf[\"Longitude\"] = pd.to_numeric(df.Longitude).replace(0, np.nan).apply(lambda x: round(x,2))\n",
    "\tdf[\"Accident\"] = df.Accident.replace({\"Yes\":True, \"No\":False})\n",
    "\tdf[\"Belts\"] = df.Belts.replace({\"Yes\":True, \"No\":False})\n",
    "\tdf[\"Personal Injury\"] = df[\"Personal Injury\"].replace({\"Yes\":True, \"No\":False})\n",
    "\tdf[\"Property Damage\"] = df[\"Property Damage\"].replace({\"Yes\":True, \"No\":False})\n",
    "\tdf[\"Fatal\"] = df[\"Fatal\"].replace({\"Yes\":True, \"No\":False})\n",
    "\tdf[\"Commercial License\"] = df[\"Commercial License\"].replace({\"Yes\":True, \"No\":False})\n",
    "\tdf[\"HAZMAT\"] = df[\"HAZMAT\"].replace({\"Yes\":True, \"No\":False})\n",
    "\tdf[\"Commercial Vehicle\"] = df[\"Commercial Vehicle\"].replace({\"Yes\":True, \"No\":False})\n",
    "\tdf[\"Alcohol\"] = df[\"Alcohol\"].replace({\"Yes\":True, \"No\":False})\n",
    "\tdf[\"Work Zone\"] = df[\"Work Zone\"].replace({\"Yes\":True, \"No\":False})\n",
    "\tdf[\"Search Conducted\"].fillna(\"No\", inplace=True)\n",
    "\tdf[\"Search Disposition\"] = df[\"Search Disposition\"].fillna(\"Not Applicable\").str.replace(\"nothing\", \"Nothing\")\n",
    "\tdf[\"Search Outcome\"].fillna(\"NA\", inplace=True)\n",
    "\t# df[\"Search Reason\"].fillna(\"Not Applicable\", inplace=True)\n",
    "\t# df[\"Search Reason For Stop\"].fillna(\"Not Applicable\", inplace=True)\n",
    "\tdf[\"Search Type\"].fillna(\"Not Applicable\", inplace=True)\n",
    "\t# df[\"Search Arrest Reason\"].fillna(\"Not Applicable\", inplace=True)\n",
    "\t# df[\"State\"].fillna(\"Not Applicable\", inplace=True)\n",
    "\tdf[\"VehicleType\"] = df[\"VehicleType\"].str.replace(\" - \", \"-\")\n",
    "\tdf.loc[(df[\"Year\"]<1960)|(df[\"Year\"]>2025), \"Year\"] = np.nan\n",
    "\tdf[\"Color\"] = df[\"Color\"].replace({\"BLUE, DARK\":\"BLUE\", \"BLUE, LIGHT\":\"BLUE\", \"GREEN, LGT\":\"GREEN\", \"GREEN, DK\":\"GREEN\"})\n",
    "\tdf[\"Violation Type\"] = df[\"Violation Type\"].replace({\"SERO\":\"ESERO\"})\n",
    "\tdf.drop_duplicates(subset=[\"SeqID\", \"Charge\"],keep=\"last\", inplace=True)\n",
    "\tdf[\"Driver City\"] = df[\"Driver City\"].replace(\"NONE\", np.nan)\n",
    "\tdf[\"Arrest Type Code\"] = df[\"Arrest Type\"].apply(lambda x: x.split(\" - \")[0])\n",
    "\tdf[\"Arrest Type Description\"] = df[\"Arrest Type\"].apply(lambda x: x.split(\" - \")[1])\n",
    "\tdf.loc[df[\"Geolocation\"]==\"(0.0, 0.0)\", \"Geolocation\"] = np.nan\n",
    "\t# df[\"Latitude\"] = df[\"Geolocation\"].apply(lambda x: x[0] if x[0]!=0 else np.nan)\n",
    "\t# df[\"Longitude\"] = df[\"Geolocation\"].apply(lambda x: x[1] if x[1]!=0 else np.nan)\n",
    "\treturn df\n",
    "\n",
    "st_time = time.time()\n",
    "engine = create_engine(\"mysql+mysqlconnector://4WbWyupWCd3hqWf.root:tNYOux4d2tMVPa1T@gateway01.ap-southeast-1.prod.aws.tidbcloud.com:4000/Traffic_Violation_DB\")\n",
    "# output_file = r\"C:\\Users\\hyuvaraj\\OneDrive - Nokia\\Learnings\\Guvi\\project_02\\Traffic_Violations_processed.csv\"\n",
    "chunks = pd.read_csv(\n",
    "    \"Traffic_Violations.csv\", \n",
    "    chunksize=500000)\n",
    "rename_col = {'SeqID': 'SeqID',\n",
    " 'Date Of Stop': 'Date_Of_Stop',\n",
    " 'Time Of Stop': 'Time_Of_Stop',\n",
    " 'Agency': 'Agency',\n",
    " 'SubAgency': 'SubAgency',\n",
    " 'Description': 'Description',\n",
    " 'Location': 'Location',\n",
    " 'Latitude': 'Latitude',\n",
    " 'Longitude': 'Longitude',\n",
    " 'Accident': 'Accident',\n",
    " 'Belts': 'Belts',\n",
    " 'Personal Injury': 'Personal_Injury',\n",
    " 'Property Damage': 'Property_Damage',\n",
    " 'Fatal': 'Fatal',\n",
    " 'Commercial License': 'Commercial_License',\n",
    " 'HAZMAT': 'HAZMAT',\n",
    " 'Commercial Vehicle': 'Commercial_Vehicle',\n",
    " 'Alcohol': 'Alcohol',\n",
    " 'Work Zone': 'Work_Zone',\n",
    " 'Search Conducted': 'Search_Conducted',\n",
    " 'Search Disposition': 'Search_Disposition',\n",
    " 'Search Outcome': 'Search_Outcome',\n",
    " 'Search Reason': 'Search_Reason',\n",
    " 'Search Reason For Stop': 'Search_Reason_For_Stop',\n",
    " 'Search Type': 'Search_Type',\n",
    " 'Search Arrest Reason': 'Search_Arrest_Reason',\n",
    " 'State': 'State',\n",
    " 'VehicleType': 'VehicleType',\n",
    " 'Year': 'Year',\n",
    " 'Make': 'Make',\n",
    " 'Model': 'Model',\n",
    " 'Color': 'Color',\n",
    " 'Violation Type': 'Violation_Type',\n",
    " 'Charge': 'Charge',\n",
    " 'Article': 'Article',\n",
    " 'Contributed To Accident': 'Contributed_To_Accident',\n",
    " 'Race': 'Race',\n",
    " 'Gender': 'Gender',\n",
    " 'Driver City': 'Driver_City',\n",
    " 'Driver State': 'Driver_State',\n",
    " 'DL State': 'DL_State',\n",
    " 'Geolocation': 'Geolocation',\n",
    " 'DateTime Of Stop': 'DateTime_Of_Stop',\n",
    " 'Arrest Type Code': 'Arrest_Type_Code',\n",
    " 'Arrest Type Description': 'Arrest_Type_Description'}\n",
    "tot_shape = 0\n",
    "for ind, df in enumerate(chunks, 1):\n",
    "\tprint(f\"Iteration: {ind} | Initiated.. | Total shape: {df.shape}\")\n",
    "\tprint(f\"Duplicate shape: {df.loc[df.duplicated()].shape} | After drop duplicates: {df.drop_duplicates(keep='first').shape}\")\n",
    "\tdf.drop_duplicates(keep='first', inplace=True)\n",
    "\tcolumnwise_cleaning(df)\n",
    "\treplace_make_values(df)\n",
    "\t\n",
    "\tdf.drop(columns=[\"Arrest Type\"], inplace=True)\n",
    "\tdf.rename(columns=rename_col, inplace=True)\n",
    "\t# df.to_sql(\"Traffic_Violation\", con=engine, if_exists=\"append\", index=False, method=\"multi\", chunksize=5000)\n",
    "\tprint(f\"{ind} | Loaded shape{df.shape}\")\n",
    "\ttot_shape += df.shape[0]\n",
    "\t# if os.path.isfile(output_file):\n",
    "\t\t# df.to_csv(output_file, index=False, header=False, mode=\"a\")\n",
    "\t# else:\n",
    "\t\t# df.to_csv(output_file, index=False, header=True, mode=\"w\")\n",
    "\tprint(\"-------------------------------------------------------------------\\n\")\n",
    "\t# break\n",
    "\n",
    "print(f\"Total shape: {tot_shape} | Overall time taken: {round((time.time()-st_time)/60, 2)} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcecf633",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Host: gateway01.ap-southeast-1.prod.aws.tidbcloud.com\n",
    "Port: 4000\n",
    "username: 4WbWyupWCd3hqWf.root\n",
    "Password: tNYOux4d2tMVPa1T\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c027ff",
   "metadata": {},
   "source": [
    "Creating DB & Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2899523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mysql-connector-python\n",
      "  Downloading mysql_connector_python-9.0.0-cp38-cp38-win_amd64.whl (14.3 MB)\n",
      "Installing collected packages: mysql-connector-python\n",
      "Successfully installed mysql-connector-python-9.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.1; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\hyuvaraj\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install mysql-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3bccc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('52282e8c-f2e1-4bb5-8509-2d5e4f8da8ca', datetime.date(2023, 5, 1), datetime.timedelta(seconds=83460), 'MCP', '3rd District, Silver Spring', 'operating unregistered motor vehicle on highway', 'BRIGGS CHANEY RD / COLUMIBA PIKE', None, None, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 'No', 'Not Applicable', 'Citation', None, '17-107(a1)', 'Not Applicable', None, 'MD', '02-Automobile', 2007, 'CHEVROLET', 'CRUZ', 'BLACK', 'Citation', '13-401(b1)', 'Transportation Article', 0, 'WHITE', 'M', 'GAITHERSBURG', 'MD', 'MD', None, datetime.datetime(2023, 5, 1, 23, 11), 'A', 'Marked Patrol'), ('b66f253b-af29-4bc4-bb73-93755ca2a779', datetime.date(2023, 8, 31), datetime.timedelta(seconds=60060), 'MCP', '6th District, Gaithersburg / Montgomery Village', 'driving to drive motor vehicle on highway without required license and authorization', 'OAKMONT AVE / GROVEMONT CIR', Decimal('39.10'), Decimal('-77.15'), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 'No', 'Not Applicable', 'Citation', None, '20-102(a1)', 'Not Applicable', None, 'MD', '02-Automobile', 2005, 'FORD', 'EXPLORER', 'BLACK', 'Citation', '16-101(a1)', 'Transportation Article', 0, 'HISPANIC', 'M', 'GAITHERSBURG', 'MD', 'MD', '(39.097965, -77.15301)', datetime.datetime(2023, 8, 31, 16, 41), 'A', 'Marked Patrol'), ('b66f253b-af29-4bc4-bb73-93755ca2a779', datetime.date(2023, 8, 31), datetime.timedelta(seconds=60060), 'MCP', '6th District, Gaithersburg / Montgomery Village', 'failure to display registration card upon demand by police officer', 'OAKMONT AVE / GROVEMONT CIR', Decimal('39.10'), Decimal('-77.15'), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 'No', 'Not Applicable', 'Citation', None, '20-102(a1)', 'Not Applicable', None, 'MD', '02-Automobile', 2005, 'FORD', 'EXPLORER', 'BLACK', 'Citation', '13-409(b)', 'Transportation Article', 0, 'HISPANIC', 'M', 'GAITHERSBURG', 'MD', 'MD', '(39.097965, -77.15301)', datetime.datetime(2023, 8, 31, 16, 41), 'A', 'Marked Patrol'), ('b66f253b-af29-4bc4-bb73-93755ca2a779', datetime.date(2023, 8, 31), datetime.timedelta(seconds=60060), 'MCP', '6th District, Gaithersburg / Montgomery Village', 'driver of motor vehicle following vehicle closer than reasonable and prudent', 'OAKMONT AVE / GROVEMONT CIR', Decimal('39.10'), Decimal('-77.15'), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 'No', 'Not Applicable', 'Citation', None, '20-102(a1)', 'Not Applicable', None, 'MD', '02-Automobile', 2005, 'FORD', 'EXPLORER', 'BLACK', 'Citation', '21-310(a)', 'Transportation Article', 0, 'HISPANIC', 'M', 'GAITHERSBURG', 'MD', 'MD', '(39.097965, -77.15301)', datetime.datetime(2023, 8, 31, 16, 41), 'A', 'Marked Patrol'), ('b66f253b-af29-4bc4-bb73-93755ca2a779', datetime.date(2023, 8, 31), datetime.timedelta(seconds=60060), 'MCP', '6th District, Gaithersburg / Montgomery Village', 'failure to control veh. speed on hwy. to avoid collision', 'OAKMONT AVE / GROVEMONT CIR', Decimal('39.10'), Decimal('-77.15'), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 'No', 'Not Applicable', 'Citation', None, '20-102(a1)', 'Not Applicable', None, 'MD', '02-Automobile', 2005, 'FORD', 'EXPLORER', 'BLACK', 'Citation', '21-801(b)', 'Transportation Article', 0, 'HISPANIC', 'M', 'GAITHERSBURG', 'MD', 'MD', '(39.097965, -77.15301)', datetime.datetime(2023, 8, 31, 16, 41), 'A', 'Marked Patrol'), ('971ef50f-f138-419f-89e5-5d2cc5d7b75a', datetime.date(2023, 4, 30), datetime.timedelta(seconds=86100), 'MCP', '4th District, Wheaton', 'driving vehicle on highway with suspended registration', 'KEMP MILL ROAD / ALPERT LANE', Decimal('39.05'), Decimal('-77.02'), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 'No', 'Not Applicable', 'Citation', None, '55*', 'Not Applicable', None, 'MD', '02-Automobile', 2013, 'HYUNDAI', 'SONATA', 'RED', 'Citation', '13-401(h)', 'Transportation Article', 0, 'WHITE', 'F', 'SILVER SPRING', 'MD', 'MD', '(39.0530383333333, -77.0246366666667)', datetime.datetime(2023, 4, 30, 23, 55), 'A', 'Marked Patrol'), ('b66f253b-af29-4bc4-bb73-93755ca2a779', datetime.date(2023, 8, 31), datetime.timedelta(seconds=60060), 'MCP', '6th District, Gaithersburg / Montgomery Village', 'failure of individual driving on highway to display license to uniformed police on demand', 'OAKMONT AVE / GROVEMONT CIR', Decimal('39.10'), Decimal('-77.15'), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 'No', 'Not Applicable', 'Citation', None, '20-102(a1)', 'Not Applicable', None, 'MD', '02-Automobile', 2005, 'FORD', 'EXPLORER', 'BLACK', 'Citation', '16-112(c)', 'Transportation Article', 0, 'HISPANIC', 'M', 'GAITHERSBURG', 'MD', 'MD', '(39.097965, -77.15301)', datetime.datetime(2023, 8, 31, 16, 41), 'A', 'Marked Patrol'), ('b66f253b-af29-4bc4-bb73-93755ca2a779', datetime.date(2023, 8, 31), datetime.timedelta(seconds=60060), 'MCP', '6th District, Gaithersburg / Montgomery Village', 'failure to stop after accident involving damage to attended veh.', 'OAKMONT AVE / GROVEMONT CIR', Decimal('39.10'), Decimal('-77.15'), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 'No', 'Not Applicable', 'Citation', None, '20-102(a1)', 'Not Applicable', None, 'MD', '02-Automobile', 2005, 'FORD', 'EXPLORER', 'BLACK', 'Citation', '20-103(a)', 'Transportation Article', 0, 'HISPANIC', 'M', 'GAITHERSBURG', 'MD', 'MD', '(39.097965, -77.15301)', datetime.datetime(2023, 8, 31, 16, 41), 'A', 'Marked Patrol'), ('b66f253b-af29-4bc4-bb73-93755ca2a779', datetime.date(2023, 8, 31), datetime.timedelta(seconds=60060), 'MCP', '6th District, Gaithersburg / Montgomery Village', 'failure to return to & remain at scene of accidentinvolving attended veh.damage', 'OAKMONT AVE / GROVEMONT CIR', Decimal('39.10'), Decimal('-77.15'), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 'No', 'Not Applicable', 'Citation', None, '20-102(a1)', 'Not Applicable', None, 'MD', '02-Automobile', 2005, 'FORD', 'EXPLORER', 'BLACK', 'Citation', '20-103(b)', 'Transportation Article', 0, 'HISPANIC', 'M', 'GAITHERSBURG', 'MD', 'MD', '(39.097965, -77.15301)', datetime.datetime(2023, 8, 31, 16, 41), 'A', 'Marked Patrol'), ('b66f253b-af29-4bc4-bb73-93755ca2a779', datetime.date(2023, 8, 31), datetime.timedelta(seconds=60060), 'MCP', '6th District, Gaithersburg / Montgomery Village', 'failure of veh. driver involved in accident to give insurance policy information', 'OAKMONT AVE / GROVEMONT CIR', Decimal('39.10'), Decimal('-77.15'), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 'No', 'Not Applicable', 'Citation', None, '20-102(a1)', 'Not Applicable', None, 'MD', '02-Automobile', 2005, 'FORD', 'EXPLORER', 'BLACK', 'Citation', '20-105.1', 'Transportation Article', 0, 'HISPANIC', 'M', 'GAITHERSBURG', 'MD', 'MD', '(39.097965, -77.15301)', datetime.datetime(2023, 8, 31, 16, 41), 'A', 'Marked Patrol'), ('b66f253b-af29-4bc4-bb73-93755ca2a779', datetime.date(2023, 8, 31), datetime.timedelta(seconds=60060), 'MCP', '6th District, Gaithersburg / Montgomery Village', 'failure to immediately stop veh. at scene of accident involving bodily injury', 'OAKMONT AVE / GROVEMONT CIR', Decimal('39.10'), Decimal('-77.15'), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 'No', 'Not Applicable', 'Citation', None, '20-102(a1)', 'Not Applicable', None, 'MD', '02-Automobile', 2005, 'FORD', 'EXPLORER', 'BLACK', 'Citation', '20-102(a1)', 'Transportation Article', 0, 'HISPANIC', 'M', 'GAITHERSBURG', 'MD', 'MD', '(39.097965, -77.15301)', datetime.datetime(2023, 8, 31, 16, 41), 'A', 'Marked Patrol'), ('b66f253b-af29-4bc4-bb73-93755ca2a779', datetime.date(2023, 8, 31), datetime.timedelta(seconds=60060), 'MCP', '6th District, Gaithersburg / Montgomery Village', 'failure to immediately return and remain at scene of accident involving bodily injury', 'OAKMONT AVE / GROVEMONT CIR', Decimal('39.10'), Decimal('-77.15'), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 'No', 'Not Applicable', 'Citation', None, '20-102(a1)', 'Not Applicable', None, 'MD', '02-Automobile', 2005, 'FORD', 'EXPLORER', 'BLACK', 'Citation', '20-102(a2)', 'Transportation Article', 0, 'HISPANIC', 'M', 'GAITHERSBURG', 'MD', 'MD', '(39.097965, -77.15301)', datetime.datetime(2023, 8, 31, 16, 41), 'A', 'Marked Patrol'), ('969c21c0-a843-4e3c-bce6-9abecd6c12f3', datetime.date(2023, 8, 31), datetime.timedelta(seconds=32340), 'MCP', '4th District, Wheaton', 'failure to stop at stop sign', 'KAYSON / ESTELLE', Decimal('39.01'), Decimal('-77.09'), 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 'No', 'Not Applicable', 'NA', None, None, 'Not Applicable', None, 'XX', '19-Moped', 2020, 'LONGBOW', 'SXR', 'RED', 'Citation', '21-707(a)', 'Transportation Article', 0, 'WHITE', 'M', 'BETHESDA', 'MD', 'MD', '(39.0127196666667, -77.0908246666667)', datetime.datetime(2023, 8, 31, 8, 59), 'A', 'Marked Patrol'), ('df65bb01-5a6f-4f67-a610-082893b1d4fe', datetime.date(2023, 9, 1), datetime.timedelta(seconds=1620), 'MCP', '5th District, Germantown', 'driving vehicle on highway with suspended registration', '13031 WISTERIA DR', Decimal('39.18'), Decimal('-77.27'), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 'No', 'Not Applicable', 'Citation', None, '13-401(h)', 'Not Applicable', None, 'MD', '02-Automobile', 2019, 'HONDA', '4S', 'GRAY', 'Citation', '13-401(h)', 'Transportation Article', 0, 'BLACK', 'M', 'GAITHERSBURG', 'MD', 'MD', '(39.1782438333333, -77.2704891666667)', datetime.datetime(2023, 9, 1, 0, 27), 'A', 'Marked Patrol'), ('969c21c0-a843-4e3c-bce6-9abecd6c12f3', datetime.date(2023, 8, 31), datetime.timedelta(seconds=32340), 'MCP', '4th District, Wheaton', 'failure to control veh. speed on hwy. to avoid collision', 'KAYSON / ESTELLE', Decimal('39.01'), Decimal('-77.09'), 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 'No', 'Not Applicable', 'NA', None, None, 'Not Applicable', None, 'XX', '19-Moped', 2020, 'LONGBOW', 'SXR', 'RED', 'Citation', '21-801(b)', 'Transportation Article', 0, 'WHITE', 'M', 'BETHESDA', 'MD', 'MD', '(39.0127196666667, -77.0908246666667)', datetime.datetime(2023, 8, 31, 8, 59), 'A', 'Marked Patrol')]\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"gateway01.ap-southeast-1.prod.aws.tidbcloud.com\",\n",
    "    port=4000,\n",
    "    user=\"4WbWyupWCd3hqWf.root\",\n",
    "    password=\"tNYOux4d2tMVPa1T\")\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "# cur.execute(\"drop TABLE Traffic_Violation_DB.`Traffic_Violation`;\")\n",
    "cur.execute(\"select * from Traffic_Violation_DB.Traffic_Violation limit 15;\")\n",
    "res=cur.fetchall()\n",
    "print(res)\n",
    "# cur.execute(\"create database if not exists Traffic_Violation_DB;\")\n",
    "# cur.execute(\"\"\"create table if not exists Traffic_Violation_DB.Traffic_Violation(\n",
    "\t# SeqID varchar(36),\n",
    "\t# Date_Of_Stop date,\n",
    "\t# Time_Of_Stop time,\n",
    "\t# Agency varchar(10),\n",
    "\t# SubAgency varchar(100),\n",
    "\t# Description varchar(250),\n",
    "\t# Location varchar(75),\n",
    "\t# Latitude decimal(8,6),\n",
    "\t# Longitude decimal(8,6),\n",
    "\t# Accident boolean,\n",
    "\t# Belts boolean,\n",
    "\t# Personal_Injury boolean,\n",
    "\t# Property_Damage boolean,\n",
    "\t# Fatal boolean,\n",
    "\t# Commercial_License boolean,\n",
    "\t# HAZMAT boolean,\n",
    "\t# Commercial_Vehicle boolean,\n",
    "\t# Alcohol boolean,\n",
    "\t# Work_Zone boolean,\n",
    "\t# Search_Conducted varchar(3),\n",
    "\t# Search_Disposition varchar(40),\n",
    "\t# Search_Outcome varchar(12),\n",
    "\t# Search_Reason varchar(30),\n",
    "\t# Search_Reason_For_Stop varchar(20),\n",
    "\t# Search_Type varchar(20),\n",
    "\t# Search_Arrest_Reason varchar(10),\n",
    "\t# `State` varchar(2),\n",
    "\t# VehicleType varchar(40),\n",
    "\t# `Year` int,\n",
    "\t# Make varchar(40),\n",
    "\t# Model varchar(40),\n",
    "\t# Color varchar(20),\n",
    "\t# Violation_Type varchar(15),\n",
    "\t# Charge varchar(40),\n",
    "\t# Article varchar(40),\n",
    "\t# Contributed_To_Accident boolean,\n",
    "\t# Race varchar(15),\n",
    "\t# Gender varchar(1),\n",
    "\t# Driver_City varchar(40),\n",
    "\t# Driver_State varchar(2),\n",
    "\t# DL_State varchar(2),\n",
    "\t# Geolocation varchar(40),\n",
    "\t# DateTime_Of_Stop datetime,\n",
    "\t# Arrest_Type_Code varchar(1),\n",
    "\t# Arrest_Type_Description varchar(80)\n",
    "    # );\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
